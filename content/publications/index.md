# Publications

<!-- citation-update: 2026-02-07 -->
<a href="https://scholar.google.co.jp/citations?user=jHXLs2wAAAAJ&hl=en"><img src="https://img.shields.io/badge/Google_Scholar-Kazuki_Fujii-4285F4?logo=google-scholar&style=flat-square" alt="Google Scholar"></a>
<span><img src="https://img.shields.io/badge/Total_Citations-208-4285F4?style=flat-square&logo=google-scholar" alt="Total Citations"></span>

## Peer-Reviewed Conference Papers

<div class="pub-entry first-author">

### **Rewriting Pre-Training Data Boosts LLM Performance in Math and Code**
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Role-First_Author-007ec6?style=flat-square" alt="First Author"></span>
  <a href="https://iclr.cc/"><img src="https://img.shields.io/badge/ICLR_2026-Main_Conference-ede1d1?style=flat-square" alt="ICLR 2026"></a>
  <a href="https://arxiv.org/abs/2505.02881"><img src="https://img.shields.io/badge/arXiv-2505.02881-b31b1b.svg?style=flat-square" alt="arXiv"></a>
  <a href="https://huggingface.co/datasets/tokyotech-llm/swallow-math"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20HF-Math_Dataset-ffd21e?style=flat-square" alt="HF Math"></a>
  <a href="https://huggingface.co/datasets/tokyotech-llm/swallow-code"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20HF-Code_Dataset-ffd21e?style=flat-square" alt="HF Code"></a>
  <span><img src="https://img.shields.io/badge/Cited_by-10-4285F4?style=flat-square&logo=google-scholar" alt="Citations: 10"></span>
</div>

* **Authors:** **Kazuki Fujii**, Yukito Tajima, Sakae Mizuki, Masaki Kawamura, Hinari Shimada, Taihei Shiotani, Koshiro Saito, Masanari Oi, Taishi Nakamura, Takumi Okamoto, Shigeki Ishida, Kakeru Hattori, Youmi Ma, Hiroya Takamura, Rio Yokota, Jun Sakuma, Naoaki Okazaki
* **Venue:** International Conference on Learning Representations (ICLR), 2026
* **Contribution:** Led the entire project lifecycle—from inception and experimental design to dataset construction.
* **Summary:** Proposed "LLM Rewriting" to synthesize high-quality pre-training data in math and code. Demonstrated that improving **style and logic** (beyond simple rephrasing) significantly boosts performance, achieving state-of-the-art results among open math/code pre-training corpora.
* **Datasets:** Released [Swallow-Math](https://huggingface.co/datasets/tokyotech-llm/swallow-math) and [Swallow-Code](https://huggingface.co/datasets/tokyotech-llm/swallow-code) (v1 & v2).

</div>

<div class="pub-entry">

### **Building Instruction-Tuning Datasets from Human-Written Instructions with Open-Weight Large Language Models**
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Role-Co--Author-777777?style=flat-square" alt="Co-Author"></span>
  <a href="https://arxiv.org/abs/2503.23714"><img src="https://img.shields.io/badge/arXiv-2503.23714-b31b1b.svg?style=flat-square" alt="arXiv"></a>
  <a href="https://colmweb.org/"><img src="https://img.shields.io/badge/COLM_2025-Main_Conference-4b44ce?style=flat-square" alt="COLM 2025"></a>
  <span><img src="https://img.shields.io/badge/Cited_by-4-4285F4?style=flat-square&logo=google-scholar" alt="Citations: 4"></span>
</div>

* **Authors:** Youmi Ma, Sakae Mizuki, **Kazuki Fujii**, Taishi Nakamura, Masanari Ohi, Hinari Shimada, Taihei Shiotani, Koshiro Saito, Koki Maeda, Kakeru Hattori, Takumi Okamoto, Shigeki Ishida, Rio Yokota, Hiroya Takamura, Naoaki Okazaki
* **Venue:** Conference on Language Modeling (COLM), 2025

</div>

<div class="pub-entry">

### **Drop-Upcycling: Training Sparse Mixture of Experts with Partial Re-initialization**
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Role-Co--Author-777777?style=flat-square" alt="Co-Author"></span>
  <a href="https://arxiv.org/abs/2502.19261"><img src="https://img.shields.io/badge/arXiv-2502.19261-b31b1b.svg?style=flat-square" alt="arXiv"></a>
  <a href="https://iclr.cc/"><img src="https://img.shields.io/badge/ICLR_2025-Main_Conference-ede1d1?style=flat-square" alt="ICLR 2025"></a>
  <span><img src="https://img.shields.io/badge/Cited_by-6-4285F4?style=flat-square&logo=google-scholar" alt="Citations: 6"></span>
</div>

* **Authors:** Taishi Nakamura, Takuya Akiba, **Kazuki Fujii**, Yusuke Oda, Rio Yokota, Jun Suzuki
* **Venue:** International Conference on Learning Representations (ICLR), 2025

</div>

<div class="pub-entry first-author">

### **Continual Pre-Training for Cross-Lingual LLM Adaptation: Enhancing Japanese Language Capabilities**
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Role-First_Author-007ec6?style=flat-square" alt="First Author"></span>
  <a href="https://arxiv.org/abs/2404.17790"><img src="https://img.shields.io/badge/arXiv-2404.17790-b31b1b.svg?style=flat-square" alt="arXiv"></a>
  <a href="https://colmweb.org/"><img src="https://img.shields.io/badge/COLM_2024-Main_Conference-4b44ce?style=flat-square" alt="COLM 2024"></a>
  <a href="https://huggingface.co/collections/tokyotech-llm/swallow"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Models-ffd21e?style=flat-square" alt="Hugging Face"></a>
  <a href="https://github.com/rioyokotalab/Megatron-Llama2"><img src="https://img.shields.io/badge/Code-GitHub-181717?logo=github&style=flat-square" alt="Code"></a>
  <span><img src="https://img.shields.io/badge/Cited_by-123-4285F4?style=flat-square&logo=google-scholar" alt="Citations: 123"></span>
</div>

* **Authors:** **Kazuki Fujii**, Taishi Nakamura, Mengsay Loem, Hiroki Iida, Masanari Ohi, Kakeru Hattori, Hirai Shota, Sakae Mizuki, Rio Yokota, Naoaki Okazaki
* **Venue:** Conference on Language Modeling (COLM), 2024

</div>

<div class="pub-entry">

### **Building a Large Japanese Web Corpus for Large Language Models**
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Role-Co--Author-777777?style=flat-square" alt="Co-Author"></span>
  <a href="https://arxiv.org/abs/2404.17733"><img src="https://img.shields.io/badge/arXiv-2404.17733-b31b1b.svg?style=flat-square" alt="arXiv"></a>
  <a href="https://colmweb.org/"><img src="https://img.shields.io/badge/COLM_2024-Main_Conference-4b44ce?style=flat-square" alt="COLM 2024"></a>
  <span><img src="https://img.shields.io/badge/Cited_by-25-4285F4?style=flat-square&logo=google-scholar" alt="Citations: 25"></span>
</div>

* **Authors:** Naoaki Okazaki, Kakeru Hattori, Hirai Shota, Hiroki Iida, Masanari Ohi, **Kazuki Fujii**, Taishi Nakamura, Mengsay Loem, Rio Yokota, Sakae Mizuki
* **Venue:** Conference on Language Modeling (COLM), 2024

</div>

---
## Workshop Papers

<div class="pub-entry">

### **Why We Build Local Large Language Models: An Observational Analysis from 35 Japanese and Multilingual LLMs**
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Role-Co--Author-777777?style=flat-square" alt="Co-Author"></span>
  <a href="https://arxiv.org/abs/2412.14471"><img src="https://img.shields.io/badge/arXiv-2412.14471-b31b1b.svg?style=flat-square" alt="arXiv"></a>
  <a href="https://colmweb.org/"><img src="https://img.shields.io/badge/COLM_2025-MELT_Workshop-4b44ce?style=flat-square" alt="COLM 2025"></a>
  <span><img src="https://img.shields.io/badge/Award-Outstanding_Paper-FFD700?style=flat-square" alt="Award"></span>
  <span><img src="https://img.shields.io/badge/Cited_by-1-4285F4?style=flat-square&logo=google-scholar" alt="Citations: 1"></span>
</div>

* **Venue:** Conference on Language Modeling (COLM) Multilingual and Equitable Language Technologies Workshop 2025
* **Award:** Outstanding Paper Award, Natural Language Processing Research Meeting of the Information Processing Society of Japan (IPSJ-NLP)

</div>

<div class="pub-entry first-author">

### **llm-recipes: A Framework for Seamless Integration and Efficient Continual Pre-Training of Large Language Models**
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Role-First_Author-007ec6?style=flat-square" alt="First Author"></span>
  <a href="https://sc24.supercomputing.org/"><img src="https://img.shields.io/badge/SC_2024-TPC_Workshop-005696?style=flat-square" alt="SC 2024"></a>
  <a href="https://github.com/okoge-kaz/llm-recipes"><img src="https://img.shields.io/badge/GitHub-Repo-181717?logo=github&style=flat-square" alt="GitHub"></a>
  <a href="https://tpc.dev/wp-content/uploads/2024/11/sc24-tpc-workshop-FUJII.pdf"><img src="https://img.shields.io/badge/Slides-View_Deck-E4405F?logo=slideshare&style=flat-square" alt="Slides"></a>
</div>

* **Venue:** SC24 (Supercomputing) Trillion Parameter Consortium (TPC) Workshop
* **Contribution:** Led the development of a custom training framework designed for **0-day support** of new LLMs not yet supported by Megatron-LM.
* **Tech Stack:** Built on **PyTorch FSDP-v1**, enabling SFT and Continual Pre-Training for any model compatible with Hugging Face Transformers.

</div>

<div class="pub-entry">

### **Heron-Bench: A Benchmark for Evaluating Vision Language Models in Japanese**
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Role-Co--Author-777777?style=flat-square" alt="Co-Author"></span>
  <a href="https://arxiv.org/abs/2404.07824"><img src="https://img.shields.io/badge/arXiv-2404.07824-b31b1b.svg?style=flat-square" alt="arXiv"></a>
  <a href="https://cvpr.thecvf.com/"><img src="https://img.shields.io/badge/CVPR_2024-Wild_Vision_Workshop-1c5c9a?style=flat-square" alt="CVPR"></a>
  <span><img src="https://img.shields.io/badge/Cited_by-15-4285F4?style=flat-square&logo=google-scholar" alt="Citations: 15"></span>
</div>

* **Authors:** Yuichi Inoue, Kento Sasaki, Yuma Ochi, **Kazuki Fujii**, Kotaro Tanahashi, Yu Yamaguchi
* **Venue:** CVPR 2024, The 3rd Workshop on Computer Vision in the Wild

</div>

---

## Preprints

<div class="pub-entry first-author">

### **Balancing Speed and Stability: The Trade-offs of FP8 vs. BF16 Training in LLMs**
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Role-First_Author-007ec6?style=flat-square" alt="First Author"></span>
  <a href="https://arxiv.org/abs/2411.08719"><img src="https://img.shields.io/badge/arXiv-2411.08719-b31b1b.svg?style=flat-square" alt="arXiv"></a>
  <span><img src="https://img.shields.io/badge/Cited_by-3-4285F4?style=flat-square&logo=google-scholar" alt="Citations: 3"></span>
</div>

* **Contribution:** Spearheaded the verification of FP8 training for the **Swallow Project** (Japanese & English Bilingual LLM).
* **Summary:** Investigated FP8 stability for **Continual Pre-training of 70B models**. While prior works focused on from scratch training, I discovered that FP8 introduces instability during the continuous training phase of Llama-3-70B and demonstrated that the default DelayedScaling in Transformer Engine v1.x is insufficient for this regime.

</div>

<div class="pub-entry">

### **LLM-jp: A Cross-organizational Project for the Research and Development of Fully Open Japanese LLMs**
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Role-Co--Author-777777?style=flat-square" alt="Co-Author"></span>
  <a href="https://arxiv.org/abs/2407.03963"><img src="https://img.shields.io/badge/arXiv-2407.03963-b31b1b.svg?style=flat-square" alt="arXiv"></a>
  <a href="https://huggingface.co/llm-jp"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Models-ffd21e?style=flat-square" alt="Hugging Face"></a>
  <span><img src="https://img.shields.io/badge/Cited_by-18-4285F4?style=flat-square&logo=google-scholar" alt="Citations: 18"></span>
</div>

* **Role:** Served as the **Lead for Pre-training, Library Development, and Distributed Training** (May 2023 - Aug 2024).
* **Summary:** Technical report on the [LLM-jp](https://llm-jp.nii.ac.jp/) initiative. I oversaw the infrastructure and training pipeline for building fully open Japanese LLMs from scratch.
* **Note:** Authors are listed in alphabetical order.

</div>

<div class="pub-entry first-author">

### **Accelerating Large Language Model Training with 4D Parallelism and Memory Consumption Estimator**
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Role-First_Author-007ec6?style=flat-square" alt="First Author"></span>
  <a href="https://arxiv.org/abs/2411.06465"><img src="https://img.shields.io/badge/arXiv-2411.06465-b31b1b.svg?style=flat-square" alt="arXiv"></a>
  <span><img src="https://img.shields.io/badge/Cited_by-3-4285F4?style=flat-square&logo=google-scholar" alt="Citations: 3"></span>
</div>

* **Authors:** **Kazuki Fujii**, Kohei Watanabe, Rio Yokota
* **Summary:** Proposed a systematic memory consumption estimator for LLM training with 4D parallelism (TP, PP, DP, CP). The estimator provides accurate per-GPU memory breakdowns covering model states, activations, and communication buffers, enabling practitioners to determine optimal parallelism configurations before launching expensive training runs.

</div>

---

## Japanese Publications

<div class="pub-entry first-author">

### **継続事前学習による日本語に強い大規模言語モデルの構築**
<div style="margin-top: -8px; margin-bottom: 8px; font-size: 0.85rem; color: var(--secondary);">(Construction of Strong Japanese LLMs through Continual Pre-training)</div>
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Role-First_Author-007ec6?style=flat-square" alt="First Author"></span>
  <a href="https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/A8-5.pdf"><img src="https://img.shields.io/badge/NLP-2024-004513?style=flat-square" alt="NLP2024"></a>
  <span><img src="https://img.shields.io/badge/Award-Excellent_Paper-FFD700?style=flat-square" alt="Award"></span>
  <a href="https://speakerdeck.com/fujiikazuki2000/yan-yu-chu-li-xue-hui-2024-ji-sok-shi-qian-xue-xi-niyoruri-ben-yu-niqiang-ida-gui-mo-yan-yu-moderunogou-zhu"><img src="https://img.shields.io/badge/Slides-View_Deck-E4405F?logo=slideshare&style=flat-square" alt="Slides"></a>
  <a href="https://huggingface.co/collections/tokyotech-llm/swallow"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Models-ffd21e?style=flat-square" alt="Hugging Face"></a>
  <a href="https://github.com/rioyokotalab/Megatron-Llama2"><img src="https://img.shields.io/badge/Code-GitHub-181717?logo=github&style=flat-square" alt="Code"></a>
</div>

* **Authors:** **藤井一喜(Kazuki Fujii)**, 中村泰士, Mengsay Loem, 飯田大貴, 大井聖也, 服部翔, 平井翔太, 水木栄, 横田理央, 岡崎直観
* **Venue:** 言語処理学会第30回年次大会 (NLP2024)
* **Award:** 優秀賞 (Selected as one of the best papers, 12/599)

</div>

<div class="pub-entry">

### **Swallowコーパス: 日本語大規模ウェブコーパス**
<div style="margin-top: -8px; margin-bottom: 8px; font-size: 0.85rem; color: var(--secondary);">(Swallow Corpus: A Large-Scale Japanese Web Corpus)</div>
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Role-Co--Author-777777?style=flat-square" alt="Co-Author"></span>
  <a href="https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/C3-3.pdf"><img src="https://img.shields.io/badge/NLP-2024-004513?style=flat-square" alt="NLP2024"></a>
  <span><img src="https://img.shields.io/badge/Award-Excellent_Paper-FFD700?style=flat-square" alt="Award"></span>
</div>

* **Authors:** 岡崎直観, 服部翔, 平井翔太, 飯田大貴, 大井聖也, **藤井一喜(Kazuki Fujii)**, 中村泰士, Mengsay Loem, 横田理央, 水木栄
* **Venue:** 言語処理学会第30回年次大会 (NLP2024)
* **Award:** 優秀賞 (Selected as one of the best papers, 12/599)

</div>

<div class="pub-entry first-author">

### **大規模言語モデルの分散並列学習**
<div style="margin-top: -8px; margin-bottom: 8px; font-size: 0.85rem; color: var(--secondary);">(Distributed Parallel Training of Large Language Models)</div>
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Role-First_Author-007ec6?style=flat-square" alt="First Author"></span>
  <a href="https://www.ipsj.or.jp/award/9faeag0000004emc-att/5J-02.pdf"><img src="https://img.shields.io/badge/IPSJ-86th-005696?style=flat-square" alt="IPSJ"></a>
  <span><img src="https://img.shields.io/badge/Award-Best_Paper-FFD700?style=flat-square" alt="Award"></span>
  <a href="https://speakerdeck.com/fujiikazuki2000/qing-bao-chu-li-xue-hui-quan-guo-da-hui-2024-da-gui-mo-yan-yu-moderunofen-san-bing-lie-xue-xi"><img src="https://img.shields.io/badge/Slides-View_Deck-E4405F?logo=slideshare&style=flat-square" alt="Slides"></a>
  <a href="https://github.com/rioyokotalab/Megatron-Llama2"><img src="https://img.shields.io/badge/Code-GitHub-181717?logo=github&style=flat-square" alt="Code"></a>
</div>

* **Authors:** **藤井一喜(Kazuki Fujii)**, 横田理央
* **Venue:** 情報処理学会 第86回全国大会 (2024)
* **Award:** 大会優秀賞 (Best Paper Award of IPSJ National Convention)

</div>

<div class="pub-entry">

### **Swallowコーパスv2: 教育的な日本語ウェブコーパスの構築**
<div style="margin-top: -8px; margin-bottom: 8px; font-size: 0.85rem; color: var(--secondary);">(Swallow Corpus v2: Building an Educational Japanese Web Corpus)</div>
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Role-Co--Author-777777?style=flat-square" alt="Co-Author"></span>
  <a href="https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/Q3-6.pdf"><img src="https://img.shields.io/badge/NLP-2025-004513?style=flat-square" alt="NLP2025"></a>
</div>

* **Authors:** 服部 翔, 岡崎 直観, 水木 栄, **藤井 一喜(Kazuki Fujii)**, 中村 泰士, 大井 聖也, (他)
* **Venue:** 言語処理学会第31回年次大会 (NLP2025)

</div>

<div class="pub-entry">

### **模倣学習による大規模言語モデルの指示チューニング**
<div style="margin-top: -8px; margin-bottom: 8px; font-size: 0.85rem; color: var(--secondary);">(Instruction Tuning of Large Language Models via Imitation Learning)</div>
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Role-Co--Author-777777?style=flat-square" alt="Co-Author"></span>
  <a href="https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/Q8-21.pdf"><img src="https://img.shields.io/badge/NLP-2025-004513?style=flat-square" alt="NLP2025"></a>
</div>

* **Authors:** Youmi Ma, 水木 栄, **藤井 一喜(Kazuki Fujii)**, 中村 泰士, 大井 聖也, (他)
* **Venue:** 言語処理学会第31回年次大会 (NLP2025)

</div>

<div class="pub-entry">

### **新聞記事からつくる 時事と社会に強い日本語LLM**
<div style="margin-top: -8px; margin-bottom: 8px; font-size: 0.85rem; color: var(--secondary);">(Building Japanese LLMs Strong in Current Events and Society from Newspaper Articles)</div>
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Role-Co--Author-777777?style=flat-square" alt="Co-Author"></span>
  <a href="https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/C10-1.pdf"><img src="https://img.shields.io/badge/NLP-2025-004513?style=flat-square" alt="NLP2025"></a>
</div>

* **Authors:** 服部 翔, 水木 栄, **藤井 一喜(Kazuki Fujii)**, 中村 泰士, (他)
* **Venue:** 言語処理学会第31回年次大会 (NLP2025)

</div>

---

## Talks

<div class="year-divider">2025</div>

<div class="pub-entry">

### **合成データパイプラインを利用したSwallow ProjectにおけるLLM性能向上**
<div style="margin-top: -8px; margin-bottom: 8px; font-size: 0.85rem; color: var(--secondary);">(Improving LLM Performance in the Swallow Project using Synthetic Data Pipelines)</div>
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Date-2025%2F09%2F04-777777?style=flat-square" alt="Date"></span>
  <span><img src="https://img.shields.io/badge/Language-Japanese-d7003a?style=flat-square" alt="Japanese"></span>
  <a href="https://speakerdeck.com/fujiikazuki2000/he-cheng-detapaipurainwoli-yong-sitaswallowprojectni-okerullmxing-neng-xiang-shang"><img src="https://img.shields.io/badge/Slides-SpeakerDeck-E4405F?logo=speakerdeck&style=flat-square" alt="Slides"></a>
  <a href="https://aws.amazon.com/jp/blogs/news/4th-gen-ai-frontier-meet-up/"><img src="https://img.shields.io/badge/Event-AWS_AI_Frontier-232f3e?logo=amazon-aws&style=flat-square" alt="Event"></a>
</div>

* **Event:** AWS AI Frontier Meetup 2025

</div>

<div class="pub-entry">

### **論文では語られないLLM開発において重要なこと ― Swallow Projectを通して**
<div style="margin-top: -8px; margin-bottom: 8px; font-size: 0.85rem; color: var(--secondary);">(Important Aspects of LLM Development Untold in Papers: Through the Swallow Project)</div>
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Date-2025%2F07%2F16-777777?style=flat-square" alt="Date"></span>
  <span><img src="https://img.shields.io/badge/Language-Japanese-d7003a?style=flat-square" alt="Japanese"></span>
  <a href="https://youtu.be/qAlj8EtCiuI?si=S09WJMiEGZlw6yY3"><img src="https://img.shields.io/badge/Video-YouTube-FF0000?logo=youtube&style=flat-square" alt="Video"></a>
  <a href="https://speakerdeck.com/fujiikazuki2000/lun-wen-dehayu-rarenaillmkai-fa-nioitezhong-yao-nakoto-swallow-projectwotong-site"><img src="https://img.shields.io/badge/Slides-SpeakerDeck-E4405F?logo=speakerdeck&style=flat-square" alt="Slides"></a>
  <a href="https://nlp-colloquium-jp.github.io/schedule/2025-07-16_kazuki-fujii/"><img src="https://img.shields.io/badge/Event-NLP_Colloquium-004513?style=flat-square" alt="Event"></a>
</div>

* **Event:** NLP Colloquium (第81回 NLPコロキウム)

</div>

<div class="pub-entry">

### **IHPCSS 2025 Lisbon**
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Date-Summer_2025-777777?style=flat-square" alt="Date"></span>
  <span><img src="https://img.shields.io/badge/Language-English-005696?style=flat-square" alt="English"></span>
  <a href="https://speakerdeck.com/fujiikazuki2000/ihpcss2025-kazuki-fujii"><img src="https://img.shields.io/badge/Slides-SpeakerDeck-E4405F?logo=speakerdeck&style=flat-square" alt="Slides"></a>
  <a href="https://ss25.ihpcss.org/"><img src="https://img.shields.io/badge/Event-IHPCSS_2025-000000?style=flat-square" alt="Event"></a>
</div>

* **Event:** International High Performance Computing Summer School (IHPCSS 2025) in Lisbon

</div>

<div class="pub-entry">

### **Amazon SageMaker HyperPod を利用した日本語 LLM (Swallow) の構築**
<div style="margin-top: -8px; margin-bottom: 8px; font-size: 0.85rem; color: var(--secondary);">(Building the Japanese LLM "Swallow" using Amazon SageMaker HyperPod)</div>
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Date-2025%2F06%2F25-777777?style=flat-square" alt="Date"></span>
  <span><img src="https://img.shields.io/badge/Language-Japanese-d7003a?style=flat-square" alt="Japanese"></span>
  <a href="https://www.youtube.com/watch?v=HnsnWjEQ6Jo&list=PLzWGOASvSx6GlBQPNhLRBDLqKgYHJHOml&index=108"><img src="https://img.shields.io/badge/Video-YouTube-FF0000?logo=youtube&style=flat-square" alt="Video"></a>
  <a href="https://speakerdeck.com/fujiikazuki2000/aws-summit-japan-2025-amazon-sagemaker-hyperpodwoli-yong-sitari-ben-yu-llm-swallow-nogou-zhu-cus-02"><img src="https://img.shields.io/badge/Slides-SpeakerDeck-E4405F?logo=speakerdeck&style=flat-square" alt="Slides"></a>
  <span><img src="https://img.shields.io/badge/Event-AWS_Summit_Japan-232f3e?logo=amazon-aws&style=flat-square" alt="Event"></span>
</div>

* **Event:** AWS Summit Japan 2025 (Session CUS-02)

</div>

<div class="year-divider">2024</div>

<div class="pub-entry">

### **Continual Pre-Training on TSUBAME for a Target Language**
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Date-2024%2F11%2F21-777777?style=flat-square" alt="Date"></span>
  <span><img src="https://img.shields.io/badge/Language-English-005696?style=flat-square" alt="English"></span>
  <a href="https://www.t4.cii.isct.ac.jp/sc24/booth_talks"><img src="https://img.shields.io/badge/Event-SC24_Booth_Talk-005696?style=flat-square" alt="Event"></a>
</div>

* **Event:** SC24 (The International Conference for High Performance Computing) Tokyo Tech Booth
* **Summary:** Introduced methodology for continual pre-training of Llama-3 (8B/70B) on TSUBAME supercomputer, focusing on efficient adaptation strategies.

</div>

<div class="pub-entry">

### **大規模モデルの学習知見**
<div style="margin-top: -8px; margin-bottom: 8px; font-size: 0.85rem; color: var(--secondary);">(Insights on Training Large-Scale Models)</div>
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Date-2024%2F11%2F13-777777?style=flat-square" alt="Date"></span>
  <span><img src="https://img.shields.io/badge/Language-Japanese-d7003a?style=flat-square" alt="Japanese"></span>
  <a href="https://www.nvidia.com/ja-jp/on-demand/session/aisummitjp24-sjp1035/?playlistId=playList-d8df4c0f-4cfe-4a9b-9a7d-e6c2c4cc5fe1"><img src="https://img.shields.io/badge/Video-NVIDIA_On--Demand-76b900?logo=nvidia&style=flat-square" alt="Video"></a>
  <a href="https://speakerdeck.com/fujiikazuki2000/da-gui-mo-yan-yu-moderunoxue-xi-zhi-jian"><img src="https://img.shields.io/badge/Slides-SpeakerDeck-E4405F?logo=speakerdeck&style=flat-square" alt="Slides"></a>
  <span><img src="https://img.shields.io/badge/Event-NVIDIA_AI_Summit-76b900?logo=nvidia&style=flat-square" alt="Event"></span>
</div>

* **Event:** NVIDIA AI Summit Japan 2024

</div>

<div class="pub-entry">

### **Google Cloud の AI Hypercomputer で学習を加速させる**
<div style="margin-top: -8px; margin-bottom: 8px; font-size: 0.85rem; color: var(--secondary);">(Accelerating Training with Google Cloud AI Hypercomputer)</div>
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Date-2024-777777?style=flat-square" alt="Date"></span>
  <span><img src="https://img.shields.io/badge/Language-Japanese-d7003a?style=flat-square" alt="Japanese"></span>
  <a href="https://youtu.be/WegKjQu-Qqs?si=VWUUf3ddXMjMJMg_"><img src="https://img.shields.io/badge/Video-YouTube-FF0000?logo=youtube&style=flat-square" alt="Video"></a>
  <span><img src="https://img.shields.io/badge/Event-Google_Cloud_Next_'24-4285F4?logo=google-cloud&style=flat-square" alt="Event"></span>
</div>

* **Event:** Google Cloud Next '24 Tokyo
* **Topic:** GENIAC 2024, H100 (A3) Cluster with Cluster Toolkit

</div>

<div class="pub-entry">

### **大規模言語モデルの分散並列学習**
<div style="margin-top: -8px; margin-bottom: 8px; font-size: 0.85rem; color: var(--secondary);">(Distributed Parallel Training of Large Language Models)</div>
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Date-2024%2F05%2F29-777777?style=flat-square" alt="Date"></span>
  <span><img src="https://img.shields.io/badge/Language-Japanese-d7003a?style=flat-square" alt="Japanese"></span>
  <a href="https://c5dc59ed978213830355fc8978.doorkeeper.jp/events/173472"><img src="https://img.shields.io/badge/Event-RIKEN_AIP-005696?style=flat-square" alt="Event"></a>
</div>

* **Event:** RIKEN AIP (理研AIP) Seminar
* **Summary:** Explained technical aspects of Data, Tensor, and Pipeline parallelism (3D Parallelism) for efficient LLM training, including real-world project examples.

</div>

<div class="pub-entry">

### **自然言語処理のための分散並列学習**
<div style="margin-top: -8px; margin-bottom: 8px; font-size: 0.85rem; color: var(--secondary);">(Distributed Parallel Training for Natural Language Processing)</div>
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Date-2024%2F03-777777?style=flat-square" alt="Date"></span>
  <span><img src="https://img.shields.io/badge/Role-Invited_Talk-FFD700?style=flat-square" alt="Invited"></span>
  <span><img src="https://img.shields.io/badge/Language-Japanese-d7003a?style=flat-square" alt="Japanese"></span>
  <a href="https://speakerdeck.com/fujiikazuki2000/zi-ran-yan-yu-chu-li-notamenofen-san-bing-lie-xue-xi-3dd9cdf8-cc6d-4350-8141-89ce35b9d273"><img src="https://img.shields.io/badge/Slides-SpeakerDeck-E4405F?logo=speakerdeck&style=flat-square" alt="Slides"></a>
  <a href="https://sites.google.com/view/llm-discussion-nlp2024-ws"><img src="https://img.shields.io/badge/Event-NLP2024_WS-004513?style=flat-square" alt="Event"></a>
</div>

* **Event:** NLP2024 Workshop (Invited Talk)

</div>

<div class="pub-entry">

### **大規模言語モデルの事前学習知見**
<div style="margin-top: -8px; margin-bottom: 8px; font-size: 0.85rem; color: var(--secondary);">(Pre-Training Insights of Large Language Models)</div>
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Date-2024%2F02-777777?style=flat-square" alt="Date"></span>
  <span><img src="https://img.shields.io/badge/Language-Japanese-d7003a?style=flat-square" alt="Japanese"></span>
  <a href="https://speakerdeck.com/fujiikazuki2000/2024-02-tokyo-tech-da-gui-mo-yan-yu-moderunoshi-qian-xue-xi-zhi-jian"><img src="https://img.shields.io/badge/Slides-SpeakerDeck-E4405F?logo=speakerdeck&style=flat-square" alt="Slides"></a>
  <a href="https://dsai.c.titech.ac.jp/dsai%E3%82%B7%E3%83%B3%E3%83%9D%E3%82%B8%E3%82%A6%E3%83%A02023%E9%96%8B%E5%82%AC%E3%81%AE%E3%81%8A%E7%9F%A5%E3%82%89%E3%81%9B/"><img src="https://img.shields.io/badge/Event-DSAI_Symposium-005696?style=flat-square" alt="Event"></a>
</div>

* **Event:** DSAI Symposium 2023 (Tokyo Tech)

</div>

---

## Books

<div class="pub-entry first-author">

### **大規模言語モデル入門 Ⅱ 〜生成型LLMの実装と評価**
<div style="margin-top: -8px; margin-bottom: 8px; font-size: 0.85rem; color: var(--secondary);">(Introduction to Large Language Models II: Implementation and Evaluation)</div>
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Role-Chapter_Author-007ec6?style=flat-square" alt="Role"></span>
  <span><img src="https://img.shields.io/badge/Publisher-Gijutsu--Hyohron-009944?style=flat-square" alt="Publisher"></span>
  <span><img src="https://img.shields.io/badge/Date-Sep_2024-777777?style=flat-square" alt="Date"></span>
  <a href="https://amzn.asia/d/aemtunI"><img src="https://img.shields.io/badge/Amazon-View_Book-FF9900?logo=amazon&style=flat-square" alt="Amazon"></a>
</div>

**Authored Chapter: Distributed Parallel Training**

I contributed as a technical author focusing on the scalability infrastructure for Large Language Models. I designed and implemented hands-on tutorials for **pre-training Llama-2 from scratch**, bridging the gap between theoretical concepts and production-grade engineering.

* **Core Topics:** Data Parallelism, DeepSpeed ZeRo, Pipeline Parallelism (PP), Tensor Parallelism (TP), and 3D Parallelism.
* **Impact:** Highly rated on Amazon Japan, serving as a definitive technical resource for LLM engineers in Japan.

</div>

---

## Technical Blogs

## Featured Articles (International)

<div class="pub-entry">

### **Developing a 172B LLM with Strong Japanese Capabilities Using NVIDIA Megatron-LM**
<div class="pub-badges">
  <a href="https://developer.nvidia.com/blog/developing-a-172b-llm-with-strong-japanese-capabilities-using-nvidia-megatron-lm/"><img src="https://img.shields.io/badge/NVIDIA-Technical_Blog-76b900?logo=nvidia&style=flat-square" alt="NVIDIA Blog"></a>
  <span><img src="https://img.shields.io/badge/Model-172B_Params-blue?style=flat-square" alt="172B"></span>
  <span><img src="https://img.shields.io/badge/Tech-FP8_Training-orange?style=flat-square" alt="FP8"></span>
  <span><img src="https://img.shields.io/badge/Hardware-H100_Cluster-76b900?style=flat-square" alt="H100"></span>
</div>

**Summary:**
As part of the GENIAC initiative by Japan's METI, I led the training of a 172 billion parameter model from scratch. We utilized **NVIDIA H100 GPUs** and achieved a **1.4x speedup** (550 TFLOP/s) by using FP8 hybrid training with Megatron-Core and Transformer Engine.

* **Links:** [English Post](https://developer.nvidia.com/blog/developing-a-172b-llm-with-strong-japanese-capabilities-using-nvidia-megatron-lm/) | [Japanese Post](https://developer.nvidia.com/ja-jp/blog/developing-a-172b-llm-with-strong-japanese-capabilities-using-nvidia-megatron-lm/)

</div>

<div class="pub-entry">

### **Training Llama 3.3 Swallow: A Japanese sovereign LLM on Amazon SageMaker HyperPod**
<div class="pub-badges">
  <a href="https://aws.amazon.com/jp/blogs/machine-learning/training-llama-3-3-swallow-a-japanese-sovereign-llm-on-amazon-sagemaker-hyperpod/"><img src="https://img.shields.io/badge/AWS-Technical_Blog-232f3e?logo=amazon-aws&style=flat-square" alt="AWS Blog"></a>
  <span><img src="https://img.shields.io/badge/Service-SageMaker_HyperPod-FF9900?style=flat-square" alt="SageMaker"></span>
  <span><img src="https://img.shields.io/badge/Model-Llama_3.3_70B-blue?style=flat-square" alt="Llama 3.3"></span>
</div>

**Summary:**
This technical report details the development of **Llama 3.3 Swallow (70B)**, which outperforms GPT-4o-mini in Japanese tasks. I discussed the infrastructure optimization on AWS SageMaker HyperPod and techniques for efficient continual pre-training.

* **Links:** [AWS Blog Post](https://aws.amazon.com/jp/blogs/machine-learning/training-llama-3-3-swallow-a-japanese-sovereign-llm-on-amazon-sagemaker-hyperpod/)

</div>

---

## Technical Articles (Japanese)

A collection of technical articles posted on **Zenn** (a popular engineering knowledge sharing platform in Japan).
<div class="pub-badges">
  <a href="https://zenn.dev/kaz20"><img src="https://img.shields.io/badge/Zenn-My_Profile-3ea8ff?logo=zenn&style=flat-square" alt="Zenn Profile"></a>
  <span><img src="https://img.shields.io/badge/Total_Likes-1400+-ff4b4b?style=flat-square" alt="Likes"></span>
</div>

### LLM Development & Training Infrastructure

**[大規模言語モデル(LLM)の作り方 Megatron-DeepSpeed編 Part1](https://zenn.dev/turing_motors/articles/04c1328bf6095a)**
<br>*(How to Build LLMs: Megatron-DeepSpeed Edition Part 1)*
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Likes-186-ff4b4b?style=flat-square" alt="Likes"></span>
  <span><img src="https://img.shields.io/badge/Tech-Megatron--LM-76b900?style=flat-square" alt="Megatron"></span>
</div>

**[Swallow: LLaMA-2 日本語継続事前学習モデル](https://zenn.dev/tokyotech_lm/articles/d6cb3a8fdfc907)**
<br>*(Swallow: LLaMA-2 Continual Pre-training for Japanese)*
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Likes-138-ff4b4b?style=flat-square" alt="Likes"></span>
  <span><img src="https://img.shields.io/badge/Model-LLaMA--2-blue?style=flat-square" alt="LLaMA-2"></span>
</div>

**[大規模言語モデル(LLM)の作り方 GPT-NeoX編 Part 1](https://zenn.dev/turing_motors/articles/dff1466194f4ac)**
<br>*(How to Build LLMs: GPT-NeoX Edition Part 1)*
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Likes-101-ff4b4b?style=flat-square" alt="Likes"></span>
  <span><img src="https://img.shields.io/badge/Tech-GPT--NeoX-green?style=flat-square" alt="NeoX"></span>
</div>

**[GENIAC: 172B 事前学習知見](https://zenn.dev/tokyotech_lm/articles/deb8012251bb68)**
<br>*(GENIAC: Insights from Pre-training a 172B Parameter Model)*
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Likes-52-ff4b4b?style=flat-square" alt="Likes"></span>
  <span><img src="https://img.shields.io/badge/Scale-172B-blue?style=flat-square" alt="172B"></span>
</div>

**[LLM開発の裏で行われるデバッグ作業: PyTorch DCP](https://zenn.dev/turing_motors/articles/04eed10b0aafe9)**
<br>*(Debugging Behind LLM Development: Deep Dive into PyTorch DCP)*
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Likes-36-ff4b4b?style=flat-square" alt="Likes"></span>
  <span><img src="https://img.shields.io/badge/Tech-Debugging-yellow?style=flat-square" alt="Debug"></span>
</div>

### Advanced Optimization & Techniques

**[FP8 trainingを支える技術 1](https://zenn.dev/kaz20/articles/52fee6a3c9ea3b)**
<br>*(Technologies Supporting FP8 Training Part 1)*
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Likes-42-ff4b4b?style=flat-square" alt="Likes"></span>
  <span><img src="https://img.shields.io/badge/Tech-FP8-orange?style=flat-square" alt="FP8"></span>
</div>

**[NVIDIA NeMoを利用したGPT-OSSの学習](https://zenn.dev/turing_motors/articles/81cf3128b22c63)**
<br>*(Training GPT-OSS using NVIDIA NeMo)*
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Likes-62-ff4b4b?style=flat-square" alt="Likes"></span>
  <span><img src="https://img.shields.io/badge/Tech-NeMo-76b900?style=flat-square" alt="NeMo"></span>
</div>

**[Kotomamba: Mamba State Space Model 分散学習ライブラリ](https://zenn.dev/kotoba_tech/articles/3eb0984d8fdfb8)**
<br>*(Kotomamba: Distributed Training Library for Mamba SSM)*
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Likes-44-ff4b4b?style=flat-square" alt="Likes"></span>
  <span><img src="https://img.shields.io/badge/Arch-Mamba_SSM-purple?style=flat-square" alt="Mamba"></span>
</div>

### Infrastructure & Tips

**[Google Cloud: HPC Toolkitにて大規模深層学習環境を整備する](https://zenn.dev/tokyotech_lm/articles/6add0efaf07427)**
<br>*(Setting up Large-Scale Deep Learning Environments with Google Cloud HPC Toolkit)*
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Cloud-Google_Cloud-4285F4?style=flat-square" alt="GCP"></span>
  <span><img src="https://img.shields.io/badge/Tool-HPC_Toolkit-blue?style=flat-square" alt="HPC"></span>
</div>

**[[Tips] PyTorchにおける動的リンク](https://zenn.dev/turing_motors/articles/3a434d046bbf48)**
<br>*(Dynamic Linking in PyTorch)*
<div class="pub-badges">
  <span><img src="https://img.shields.io/badge/Likes-57-ff4b4b?style=flat-square" alt="Likes"></span>
  <span><img src="https://img.shields.io/badge/Tech-PyTorch-EE4C2C?style=flat-square" alt="PyTorch"></span>
</div>
