# Publications

## Peer-Reviewed Conference Papers

---

## Workshop Papers

### **Why We Build Local Large Language Models: An Observational Analysis from 35 Japanese and Multilingual LLMs**
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Role-First_Author-007ec6?style=flat-square" alt="First Author"></span>
  <a href="https://arxiv.org/abs/2412.14471"><img src="https://img.shields.io/badge/arXiv-2412.14471-b31b1b.svg?style=flat-square" alt="arXiv"></a>
  <a href="https://colmweb.org/"><img src="https://img.shields.io/badge/COLM_2025-MELT_Workshop-4b44ce?style=flat-square" alt="COLM 2025"></a>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Award-Outstanding_Paper-FFD700?style=flat-square" alt="Award"></span>
  <a href="YOUR_SLIDE_LINK_HERE"><img src="https://img.shields.io/badge/Slides-View_Deck-E4405F?logo=slideshare&style=flat-square" alt="Slides"></a>
</div>

* **Venue:** Conference on Language Modeling (COLM) Multilingual and Equitable Language Technologies Workshop 2025
* **Award:** Outstanding Paper Award, Natural Language Processing Research Meeting of the Information Processing Society of Japan (IPSJ-NLP)

### **llm-recipes: A Framework for Seamless Integration and Efficient Continual Pre-Training of Large Language Models**
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Role-Co--Author-777777?style=flat-square" alt="Co-Author"></span>
  <a href="https://sc24.supercomputing.org/"><img src="https://img.shields.io/badge/SC_2024-TPC_Workshop-005696?style=flat-square" alt="SC 2024"></a>
  <a href="https://github.com/"><img src="https://img.shields.io/badge/GitHub-Repo-181717?logo=github&style=flat-square" alt="GitHub"></a>
  <a href="YOUR_SLIDE_LINK_HERE"><img src="https://img.shields.io/badge/Slides-View_Deck-E4405F?logo=slideshare&style=flat-square" alt="Slides"></a>
</div>

* **Venue:** The International Conference for High Performance Computing, Networking, Storage, and Analysis (SC24), Trillion Parameter Consortium (TPC) Workshop

---

## Preprints

### **Rewriting Pre-Training Data Boosts LLM Performance in Math and Code**
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Role-Co--Author-777777?style=flat-square" alt="Co-Author"></span>
  <a href="https://arxiv.org/abs/2505.02881"><img src="https://img.shields.io/badge/arXiv-2505.02881-b31b1b.svg?style=flat-square" alt="arXiv"></a>
  <a href="LINK"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Models-ffd21e?style=flat-square" alt="Hugging Face"></a>
  <a href="LINK"><img src="https://img.shields.io/badge/Code-GitHub-181717?logo=github&style=flat-square" alt="Code"></a>
</div>

* **Date:** 2025 (arXiv:2505.02881 [cs.LG])

### **Balancing Speed and Stability: The Trade-offs of FP8 vs. BF16 Training in LLMs**
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Role-Co--Author-777777?style=flat-square" alt="Co-Author"></span>
  <a href="https://arxiv.org/abs/2411.08719"><img src="https://img.shields.io/badge/arXiv-2411.08719-b31b1b.svg?style=flat-square" alt="arXiv"></a>
</div>

* **Date:** 2024 (arXiv:2411.08719 [cs.LG])

### **LLM-jp: A Cross-organizational Project for the Research and Development of Fully Open Japanese LLMs**
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Role-Co--Author-777777?style=flat-square" alt="Co-Author"></span>
  <a href="https://arxiv.org/abs/2407.03963"><img src="https://img.shields.io/badge/arXiv-2407.03963-b31b1b.svg?style=flat-square" alt="arXiv"></a>
  <a href="LINK"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Models-ffd21e?style=flat-square" alt="Hugging Face"></a>
</div>

* **Date:** 2024 (arXiv:2407.03963 [cs.CL])
* **Note:** Authors are listed in alphabetical order.

---

## Japanese Publications

### **継続事前学習による日本語に強い大規模言語モデルの構築**
(英訳: )

<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Role-First_Author-007ec6?style=flat-square" alt="First Author"></span>
  <a href="https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/A8-5.pdf"><img src="https://img.shields.io/badge/NLP-2024-004513?style=flat-square" alt="NLP2024"></a>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Award-Excellent_Paper-FFD700?style=flat-square" alt="Award"></span>
  <a href="https://speakerdeck.com/fujiikazuki2000/yan-yu-chu-li-xue-hui-2024-ji-sok-shi-qian-xue-xi-niyoruri-ben-yu-niqiang-ida-gui-mo-yan-yu-moderunogou-zhu"><img src="https://img.shields.io/badge/Slides-View_Deck-E4405F?logo=slideshare&style=flat-square" alt="Slides"></a>
  <a href="https://huggingface.co/collections/tokyotech-llm/swallow"><img src="https://img.shields.io/badge/%F0%9F%A4%97%20Hugging%20Face-Models-ffd21e?style=flat-square" alt="Hugging Face"></a>
  <a href="https://github.com/rioyokotalab/Megatron-Llama2"><img src="https://img.shields.io/badge/Code-GitHub-181717?logo=github&style=flat-square" alt="Code"></a>
</div>

* **Authors:** **藤井一喜(Kazuki Fujii)**, 中村泰士, Mengsay Loem, 飯田大貴, 大井聖也, 服部翔, 平井翔太, 水木栄, 横田理央, 岡崎直観
* **Venue:** 言語処理学会第30回年次大会 (NLP2024)
* **Award:** 優秀賞 (Selected as one of the best papers, 12/599)

### **Swallowコーパス: 日本語大規模ウェブコーパス**
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Role-Co--Author-777777?style=flat-square" alt="Co-Author"></span>
  <a href="https://www.anlp.jp/proceedings/annual_meeting/2024/pdf_dir/C3-3.pdf"><img src="https://img.shields.io/badge/NLP-2024-004513?style=flat-square" alt="NLP2024"></a>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Award-Excellent_Paper-FFD700?style=flat-square" alt="Award"></span>
</div>

* **Authors:** 岡崎直観, 服部翔, 平井翔太, 飯田大貴, 大井聖也, **藤井一喜(Kazuki Fujii)**, 中村泰士, Mengsay Loem, 横田理央, 水木栄
* **Venue:** 言語処理学会第30回年次大会 (NLP2024)
* **Award:** 優秀賞 (Selected as one of the best papers, 12/599)


### **大規模言語モデルの分散並列学習**
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Role-First_Author-007ec6?style=flat-square" alt="First Author"></span>
  <a href="https://www.ipsj.or.jp/award/9faeag0000004emc-att/5J-02.pdf"><img src="https://img.shields.io/badge/IPSJ-86th-005696?style=flat-square" alt="IPSJ"></a>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Award-Best_Paper-FFD700?style=flat-square" alt="Award"></span>
  <a href="https://speakerdeck.com/fujiikazuki2000/qing-bao-chu-li-xue-hui-quan-guo-da-hui-2024-da-gui-mo-yan-yu-moderunofen-san-bing-lie-xue-xi"><img src="https://img.shields.io/badge/Slides-View_Deck-E4405F?logo=slideshare&style=flat-square" alt="Slides"></a>
  <a href="https://github.com/rioyokotalab/Megatron-Llama2"><img src="https://img.shields.io/badge/Code-GitHub-181717?logo=github&style=flat-square" alt="Code"></a>
</div>

* **Authors:** **藤井一喜(Kazuki Fujii)**, 横田理央
* **Venue:** 情報処理学会 第86回全国大会 (2024)
* **Award:** 大会優秀賞 (Best Paper Award of IPSJ National Convention)

### **Swallowコーパスv2: 教育的な日本語ウェブコーパスの構築**
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Role-Co--Author-777777?style=flat-square" alt="Co-Author"></span>
  <a href="https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/Q3-6.pdf"><img src="https://img.shields.io/badge/NLP-2025-004513?style=flat-square" alt="NLP2025"></a>
</div>

* **Authors:** 服部 翔, 岡崎 直観, 水木 栄, **藤井 一喜(Kazuki Fujii)**, 中村 泰士, 大井 聖也, (他)
* **Venue:** 言語処理学会第31回年次大会 (NLP2025)

### **模倣学習による大規模言語モデルの指示チューニング**
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Role-Co--Author-777777?style=flat-square" alt="Co-Author"></span>
  <a href="https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/Q8-21.pdf"><img src="https://img.shields.io/badge/NLP-2025-004513?style=flat-square" alt="NLP2025"></a>
</div>

* **Authors:** Youmi Ma, 水木 栄, **藤井 一喜(Kazuki Fujii)**, 中村 泰士, 大井 聖也, (他)
* **Venue:** 言語処理学会第31回年次大会 (NLP2025)

### **新聞記事からつくる 時事と社会に強い日本語LLM**
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Role-Co--Author-777777?style=flat-square" alt="Co-Author"></span>
  <a href="https://www.anlp.jp/proceedings/annual_meeting/2025/pdf_dir/C10-1.pdf"><img src="https://img.shields.io/badge/NLP-2025-004513?style=flat-square" alt="NLP2025"></a>
</div>

* **Authors:** 服部 翔, 水木 栄, **藤井 一喜(Kazuki Fujii)**, 中村 泰士, (他)
* **Venue:** 言語処理学会第31回年次大会 (NLP2025)

---

## Talks

---2025---

### **合成データパイプラインを利用したSwallow ProjectにおけるLLM性能向上**
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -15px;">(Improving LLM Performance in the Swallow Project using Synthetic Data Pipelines)</div>
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -5px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Date-2025%2F09%2F04-777777?style=flat-square" alt="Date"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Language-Japanese-d7003a?style=flat-square" alt="Japanese"></span>
  <a href="https://speakerdeck.com/fujiikazuki2000/he-cheng-detapaipurainwoli-yong-sitaswallowprojectni-okerullmxing-neng-xiang-shang"><img src="https://img.shields.io/badge/Slides-SpeakerDeck-E4405F?logo=speakerdeck&style=flat-square" alt="Slides"></a>
  <a href="https://aws.amazon.com/jp/blogs/news/4th-gen-ai-frontier-meet-up/"><img src="https://img.shields.io/badge/Event-AWS_AI_Frontier-232f3e?logo=amazon-aws&style=flat-square" alt="Event"></a>
</div>

* **Event:** AWS AI Frontier Meetup 2025

### **論文では語られないLLM開発において重要なこと ― Swallow Projectを通して**
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -15px;">
(Important Aspects of LLM Development Untold in Papers: Through the Swallow Project)</div>
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -5px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Date-2025%2F07%2F16-777777?style=flat-square" alt="Date"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Language-Japanese-d7003a?style=flat-square" alt="Japanese"></span>
  <a href="https://youtu.be/qAlj8EtCiuI?si=S09WJMiEGZlw6yY3"><img src="https://img.shields.io/badge/Video-YouTube-FF0000?logo=youtube&style=flat-square" alt="Video"></a>
  <a href="https://speakerdeck.com/fujiikazuki2000/lun-wen-dehayu-rarenaillmkai-fa-nioitezhong-yao-nakoto-swallow-projectwotong-site"><img src="https://img.shields.io/badge/Slides-SpeakerDeck-E4405F?logo=speakerdeck&style=flat-square" alt="Slides"></a>
  <a href="https://nlp-colloquium-jp.github.io/schedule/2025-07-16_kazuki-fujii/"><img src="https://img.shields.io/badge/Event-NLP_Colloquium-004513?style=flat-square" alt="Event"></a>
</div>

* **Event:** NLP Colloquium (第81回 NLPコロキウム)

### **IHPCSS 2025 Lisbon**
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -15px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Date-Summer_2025-777777?style=flat-square" alt="Date"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Language-English-005696?style=flat-square" alt="English"></span>
  <a href="https://speakerdeck.com/fujiikazuki2000/ihpcss2025-kazuki-fujii"><img src="https://img.shields.io/badge/Slides-SpeakerDeck-E4405F?logo=speakerdeck&style=flat-square" alt="Slides"></a>
  <a href="https://ss25.ihpcss.org/"><img src="https://img.shields.io/badge/Event-IHPCSS_2025-000000?style=flat-square" alt="Event"></a>
</div>

* **Event:** International High Performance Computing Summer School (IHPCSS 2025) in Lisbon

### **Amazon SageMaker HyperPod を利用した日本語 LLM (Swallow) の構築**
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -15px;">
(Building the Japanese LLM "Swallow" using Amazon SageMaker HyperPod)*</div>
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -5px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Date-2025%2F06%2F25-777777?style=flat-square" alt="Date"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Language-Japanese-d7003a?style=flat-square" alt="Japanese"></span>
  <a href="https://www.youtube.com/watch?v=HnsnWjEQ6Jo&list=PLzWGOASvSx6GlBQPNhLRBDLqKgYHJHOml&index=108"><img src="https://img.shields.io/badge/Video-YouTube-FF0000?logo=youtube&style=flat-square" alt="Video"></a>
  <a href="https://speakerdeck.com/fujiikazuki2000/aws-summit-japan-2025-amazon-sagemaker-hyperpodwoli-yong-sitari-ben-yu-llm-swallow-nogou-zhu-cus-02"><img src="https://img.shields.io/badge/Slides-SpeakerDeck-E4405F?logo=speakerdeck&style=flat-square" alt="Slides"></a>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Event-AWS_Summit_Japan-232f3e?logo=amazon-aws&style=flat-square" alt="Event"></span>
</div>

* **Event:** AWS Summit Japan 2025 (Session CUS-02)


---
--- 2024 ---

### **Continual Pre-Training on TSUBAME for a Target Language**
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -15px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Date-2024%2F11%2F21-777777?style=flat-square" alt="Date"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Language-English-005696?style=flat-square" alt="English"></span>
  <a href="https://www.t4.cii.isct.ac.jp/sc24/booth_talks"><img src="https://img.shields.io/badge/Event-SC24_Booth_Talk-005696?style=flat-square" alt="Event"></a>
</div>

* **Event:** SC24 (The International Conference for High Performance Computing) Tokyo Tech Booth
* **Summary:** Introduced methodology for continual pre-training of Llama-3 (8B/70B) on TSUBAME supercomputer, focusing on efficient adaptation strategies.

### **大規模モデルの学習知見**
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -15px;">
(Insights on Training Large-Scale Models)</div>
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -5px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Date-2024%2F11%2F13-777777?style=flat-square" alt="Date"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Language-Japanese-d7003a?style=flat-square" alt="Japanese"></span>
  <a href="https://www.nvidia.com/ja-jp/on-demand/session/aisummitjp24-sjp1035/?playlistId=playList-d8df4c0f-4cfe-4a9b-9a7d-e6c2c4cc5fe1"><img src="https://img.shields.io/badge/Video-NVIDIA_On--Demand-76b900?logo=nvidia&style=flat-square" alt="Video"></a>
  <a href="https://speakerdeck.com/fujiikazuki2000/da-gui-mo-yan-yu-moderunoxue-xi-zhi-jian"><img src="https://img.shields.io/badge/Slides-SpeakerDeck-E4405F?logo=speakerdeck&style=flat-square" alt="Slides"></a>
</div>

* **Event:** NVIDIA AI Summit Japan 2024 <div><img src="https://img.shields.io/badge/Event-NVIDIA_AI_Summit-76b900?logo=nvidia&style=flat-square" alt="Event"></div>

### **Google Cloud の AI Hypercomputer で学習を加速させる**
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -15px;">
(Accelerating Training with Google Cloud AI Hypercomputer)</div>
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -5px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Date-2024-777777?style=flat-square" alt="Date"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Language-Japanese-d7003a?style=flat-square" alt="Japanese"></span>
  <a href="https://youtu.be/WegKjQu-Qqs?si=VWUUf3ddXMjMJMg_"><img src="https://img.shields.io/badge/Video-YouTube-FF0000?logo=youtube&style=flat-square" alt="Video"></a>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Event-Google_Cloud_Next_'24-4285F4?logo=google-cloud&style=flat-square" alt="Event"></span>
</div>

* **Event:** Google Cloud Next '24 Tokyo
* **Topic:** GENIAC 2024, H100 (A3) Cluster with Cluster Toolkit

### **大規模言語モデルの分散並列学習**
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -15px;">
(Distributed Parallel Training of Large Language Models)</div>
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -5px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Date-2024%2F05%2F29-777777?style=flat-square" alt="Date"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Language-Japanese-d7003a?style=flat-square" alt="Japanese"></span>
  <a href="https://c5dc59ed978213830355fc8978.doorkeeper.jp/events/173472"><img src="https://img.shields.io/badge/Event-RIKEN_AIP-005696?style=flat-square" alt="Event"></a>
</div>

* **Event:** RIKEN AIP (理研AIP) Seminar
* **Summary:** Explained technical aspects of Data, Tensor, and Pipeline parallelism (3D Parallelism) for efficient LLM training, including real-world project examples.

### **自然言語処理のための分散並列学習**
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -15px;">
(Distributed Parallel Training for Natural Language Processing)</div>
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -5px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Date-2024%2F03-777777?style=flat-square" alt="Date"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Role-Invited_Talk-FFD700?style=flat-square" alt="Invited"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Language-Japanese-d7003a?style=flat-square" alt="Japanese"></span>
  <a href="https://speakerdeck.com/fujiikazuki2000/zi-ran-yan-yu-chu-li-notamenofen-san-bing-lie-xue-xi-3dd9cdf8-cc6d-4350-8141-89ce35b9d273"><img src="https://img.shields.io/badge/Slides-SpeakerDeck-E4405F?logo=speakerdeck&style=flat-square" alt="Slides"></a>
  <a href="https://sites.google.com/view/llm-discussion-nlp2024-ws"><img src="https://img.shields.io/badge/Event-NLP2024_WS-004513?style=flat-square" alt="Event"></a>
</div>

* **Event:** NLP2024 Workshop (Invited Talk)

### **大規模言語モデルの事前学習知見**
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -15px;">
(Pre-Training Insights of Large Language Models)</div>
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -5px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Date-2024%2F02-777777?style=flat-square" alt="Date"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Language-Japanese-d7003a?style=flat-square" alt="Japanese"></span>
  <a href="https://speakerdeck.com/fujiikazuki2000/2024-02-tokyo-tech-da-gui-mo-yan-yu-moderunoshi-qian-xue-xi-zhi-jian"><img src="https://img.shields.io/badge/Slides-SpeakerDeck-E4405F?logo=speakerdeck&style=flat-square" alt="Slides"></a>
  <a href="https://dsai.c.titech.ac.jp/dsai%E3%82%B7%E3%83%B3%E3%83%9D%E3%82%B8%E3%82%A6%E3%83%A02023%E9%96%8B%E5%82%AC%E3%81%AE%E3%81%8A%E7%9F%A5%E3%82%89%E3%81%9B/"><img src="https://img.shields.io/badge/Event-DSAI_Symposium-005696?style=flat-square" alt="Event"></a>
</div>

* **Event:** DSAI Symposium 2023 (Tokyo Tech)

---

## Books

### **大規模言語モデル入門 Ⅱ 〜生成型LLMの実装と評価**
<div style="color: #666; font-size: 0.9em; margin-top: -15px; margin-bottom: 10px;">(Introduction to Large Language Models II: Implementation and Evaluation)</div>
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Role-Chapter_Author-007ec6?style=flat-square" alt="Role"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Publisher-Gijutsu--Hyohron-009944?style=flat-square" alt="Publisher"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Date-Sep_2024-777777?style=flat-square" alt="Date"></span>
  <a href="https://amzn.asia/d/aemtunI"><img src="https://img.shields.io/badge/Amazon-View_Book-FF9900?logo=amazon&style=flat-square" alt="Amazon"></a>
</div>

**Authored Chapter: Distributed Parallel Training**

I contributed as a technical author focusing on the scalability infrastructure for Large Language Models. I designed and implemented hands-on tutorials for **pre-training Llama-2 from scratch**, bridging the gap between theoretical concepts and production-grade engineering.

* **Core Topics:** Data Parallelism, DeepSpeed ZeRo, Pipeline Parallelism (PP), Tensor Parallelism (TP), and 3D Parallelism.
* **Impact:** Highly rated on Amazon Japan, serving as a definitive technical resource for LLM engineers in Japan.

---

## Technical Blogs

## Featured Articles (International)

### **Developing a 172B LLM with Strong Japanese Capabilities Using NVIDIA Megatron-LM**
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <a href="https://developer.nvidia.com/blog/developing-a-172b-llm-with-strong-japanese-capabilities-using-nvidia-megatron-lm/"><img src="https://img.shields.io/badge/NVIDIA-Technical_Blog-76b900?logo=nvidia&style=flat-square" alt="NVIDIA Blog"></a>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Model-172B_Params-blue?style=flat-square" alt="172B"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Tech-FP8_Training-orange?style=flat-square" alt="FP8"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Hardware-H100_Cluster-76b900?style=flat-square" alt="H100"></span>
</div>

**Summary:**
As part of the GENIAC initiative by Japan's METI, I led the training of a 172 billion parameter model from scratch. We utilized **NVIDIA H100 GPUs** and achieved a **1.4x speedup** (550 TFLOP/s) by using FP8 hybrid training with Megatron-Core and Transformer Engine.

* **Links:** [English Post](https://developer.nvidia.com/blog/developing-a-172b-llm-with-strong-japanese-capabilities-using-nvidia-megatron-lm/) | [Japanese Post](https://developer.nvidia.com/ja-jp/blog/developing-a-172b-llm-with-strong-japanese-capabilities-using-nvidia-megatron-lm/)

---

### **Training Llama 3.3 Swallow: A Japanese sovereign LLM on Amazon SageMaker HyperPod**
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <a href="https://aws.amazon.com/jp/blogs/machine-learning/training-llama-3-3-swallow-a-japanese-sovereign-llm-on-amazon-sagemaker-hyperpod/"><img src="https://img.shields.io/badge/AWS-Technical_Blog-232f3e?logo=amazon-aws&style=flat-square" alt="AWS Blog"></a>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Service-SageMaker_HyperPod-FF9900?style=flat-square" alt="SageMaker"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Model-Llama_3.3_70B-blue?style=flat-square" alt="Llama 3.3"></span>
</div>

**Summary:**
This technical report details the development of **Llama 3.3 Swallow (70B)**, which outperforms GPT-4o-mini in Japanese tasks. I discussed the infrastructure optimization on AWS SageMaker HyperPod and techniques for efficient continual pre-training.

* **Links:** [AWS Blog Post](https://aws.amazon.com/jp/blogs/machine-learning/training-llama-3-3-swallow-a-japanese-sovereign-llm-on-amazon-sagemaker-hyperpod/)

---

## Technical Articles (Japanese)

A collection of technical articles posted on **Zenn** (a popular engineering knowledge sharing platform in Japan).
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <a href="https://zenn.dev/kaz20"><img src="https://img.shields.io/badge/Zenn-My_Profile-3ea8ff?logo=zenn&style=flat-square" alt="Zenn Profile"></a>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Total_Likes-1400+-ff4b4b?style=flat-square" alt="Likes"></span>
</div>

### **LLM Development & Training Infrastructure**

**[大規模言語モデル(LLM)の作り方 Megatron-DeepSpeed編 Part1](https://zenn.dev/turing_motors/articles/04c1328bf6095a)**
<br>*(How to Build LLMs: Megatron-DeepSpeed Edition Part 1)*
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Likes-186-ff4b4b?style=flat-square" alt="Likes"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Tech-Megatron--LM-76b900?style=flat-square" alt="Megatron"></span>
</div>

**[Swallow: LLaMA-2 日本語継続事前学習モデル](https://zenn.dev/tokyotech_lm/articles/d6cb3a8fdfc907)**
<br>*(Swallow: LLaMA-2 Continual Pre-training for Japanese)*
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Likes-138-ff4b4b?style=flat-square" alt="Likes"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Model-LLaMA--2-blue?style=flat-square" alt="LLaMA-2"></span>
</div>

**[大規模言語モデル(LLM)の作り方 GPT-NeoX編 Part 1](https://zenn.dev/turing_motors/articles/dff1466194f4ac)**
<br>*(How to Build LLMs: GPT-NeoX Edition Part 1)*
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Likes-101-ff4b4b?style=flat-square" alt="Likes"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Tech-GPT--NeoX-green?style=flat-square" alt="NeoX"></span>
</div>

**[GENIAC: 172B 事前学習知見](https://zenn.dev/tokyotech_lm/articles/deb8012251bb68)**
<br>*(GENIAC: Insights from Pre-training a 172B Parameter Model)*
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Likes-52-ff4b4b?style=flat-square" alt="Likes"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Scale-172B-blue?style=flat-square" alt="172B"></span>
</div>

**[LLM開発の裏で行われるデバッグ作業: PyTorch DCP](https://zenn.dev/turing_motors/articles/04eed10b0aafe9)**
<br>*(Debugging Behind LLM Development: Deep Dive into PyTorch DCP)*
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Likes-36-ff4b4b?style=flat-square" alt="Likes"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Tech-Debugging-yellow?style=flat-square" alt="Debug"></span>
</div>

### **Advanced Optimization & Techniques**

**[FP8 trainingを支える技術 1](https://zenn.dev/kaz20/articles/52fee6a3c9ea3b)**
<br>*(Technologies Supporting FP8 Training Part 1)*
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Likes-42-ff4b4b?style=flat-square" alt="Likes"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Tech-FP8-orange?style=flat-square" alt="FP8"></span>
</div>

**[NVIDIA NeMoを利用したGPT-OSSの学習](https://zenn.dev/turing_motors/articles/81cf3128b22c63)**
<br>*(Training GPT-OSS using NVIDIA NeMo)*
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Likes-62-ff4b4b?style=flat-square" alt="Likes"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Tech-NeMo-76b900?style=flat-square" alt="NeMo"></span>
</div>

**[Kotomamba: Mamba State Space Model 分散学習ライブラリ](https://zenn.dev/kotoba_tech/articles/3eb0984d8fdfb8)**
<br>*(Kotomamba: Distributed Training Library for Mamba SSM)*
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Likes-44-ff4b4b?style=flat-square" alt="Likes"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Arch-Mamba_SSM-purple?style=flat-square" alt="Mamba"></span>
</div>

### **Infrastructure & Tips**

**[Google Cloud: HPC Toolkitにて大規模深層学習環境を整備する](https://zenn.dev/tokyotech_lm/articles/6add0efaf07427)**
<br>*(Setting up Large-Scale Deep Learning Environments with Google Cloud HPC Toolkit)*
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Cloud-Google_Cloud-4285F4?style=flat-square" alt="GCP"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Tool-HPC_Toolkit-blue?style=flat-square" alt="HPC"></span>
</div>

**[[Tips] PyTorchにおける動的リンク](https://zenn.dev/turing_motors/articles/3a434d046bbf48)**
<br>*(Dynamic Linking in PyTorch)*
<div style="display: flex; flex-wrap: wrap; gap: 5px; align-items: center; margin-top: -20px;">
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Likes-57-ff4b4b?style=flat-square" alt="Likes"></span>
  <span style="display: inline-block;"><img src="https://img.shields.io/badge/Tech-PyTorch-EE4C2C?style=flat-square" alt="PyTorch"></span>
</div>
